{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYOM In-Vantage Scoring with PMML and ONNX\n",
    "\n",
    "In this notebook, we will show you how to work with the Bring Your Own Model (BYOM) pattern and BYOM In-Vantage Scoring. This pattern allows you to use whatever data science platform you want to perform model development and experimentation. You can use the vast majority of popular data science libraries and transformations. The only constraint is that you can convert it to one of the following open formats\n",
    "\n",
    "- ONNX\n",
    "- PMML\n",
    "- H2O (MOJO)\n",
    "- H2O (Driverless AI)\n",
    "\n",
    "ONNX is become more popular by the day. It is a very efficient model format which was created and is maintained by Microsoft and its adoption by other companies and libraries as the standard open format is incresingly rapidly. While the name suggests it is primarily related to neural networks, it can be used with most sklearn libraries and algorithms. \n",
    "\n",
    "\n",
    "In this example, we will show you how you can develop in a notebook or other third-party tooling, produce a model and convert it to both `onnx` and `pmml` formats for deploying in Vantage with ModelOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt\n",
    "!{sys.executable} -m pip install xgboost==0.90 nyoka==4.3.0\n",
    "!{sys.executable} -m pip install onnx==1.10.2 skl2onnx==1.11.2 onnxruntime==1.9.0 protobuf==3.20.1 onnxmltools==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import getpass\n",
    "\n",
    "from teradataml import (\n",
    "    create_context, \n",
    "    remove_context,\n",
    "    get_context,\n",
    "    get_connection,\n",
    "    DataFrame,\n",
    "    retrieve_byom,\n",
    "    PMMLPredict,\n",
    "    configure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = input(\"Host: \")\n",
    "username = input(\"Username: \")\n",
    "password = getpass.getpass(\"Password: \")\n",
    "val_db = input(\"VAL DB: \")\n",
    "byom_db = input(\"BYOM DB: \")\n",
    "\n",
    "# configure byom/val installation\n",
    "configure.val_install_location = val_db\n",
    "configure.byom_install_location = byom_db\n",
    "\n",
    "# by default we assume your are using your user database. change as required\n",
    "database = username\n",
    "\n",
    "create_context(host=host, username=username, password=password, logmech=\"TDNEGO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "train_pdf = DataFrame.from_query(\"\"\"\n",
    "SELECT \n",
    "    F.*, D.hasdiabetes \n",
    "FROM pima_patient_features F\n",
    "JOIN pima_patient_diagnoses D\n",
    "    ON F.patientid = D.patientid \n",
    "    WHERE F.patientid MOD 5 <> 0\n",
    "\"\"\").to_pandas(all_rows=True)\n",
    "\n",
    "features = [\"NumTimesPrg\", \"Age\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\"]\n",
    "target = \"HasDiabetes\"\n",
    "\n",
    "# split data into X and y\n",
    "X_train = train_pdf[features]\n",
    "y_train = train_pdf[target]\n",
    "\n",
    "model = Pipeline([('scaler', MinMaxScaler()),\n",
    "                  ('xgb', XGBClassifier(eta=0.2, max_depth=6))])\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the model to PMML\n",
    "\n",
    "You can use the sklearn2pmml or the nyoka python libraries to convert to pmml. The nyoka is a python only package and so it is preferrable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyoka import xgboost_to_pmml\n",
    "\n",
    "xgboost_to_pmml(pipeline=model, col_names=features, target_name=target, pmml_f_name=\"model.pmml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the model to ONNX\n",
    "\n",
    "We can also convert the model to onnx format. This is a bit more involved as the client libraries for converting from sklearn/xgboost to onnx are not yet as mature.\n",
    "\n",
    "```\n",
    "pip install onnx==1.10.2 skl2onnx==1.11.2 onnxruntime==1.9.0 protobuf==3.20.1 onnxmltools==1.7.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx import convert_sklearn, to_onnx, update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import (\n",
    "    calculate_linear_classifier_output_shapes,\n",
    "    calculate_linear_regressor_output_shapes)\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "from onnxmltools.convert import convert_xgboost as convert_xgboost_booster\n",
    "\n",
    "update_registered_converter(\n",
    "    XGBClassifier, 'XGBoostXGBClassifier',\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})\n",
    "\n",
    "\n",
    "model_onnx = to_onnx(model, X_train.astype(np.float32), target_opset=15)\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import into ModelOps to Operationalize\n",
    "\n",
    "Go to the ModelOps UI and import this as a new model version. Then follow the workflow to deploy. Note that you can also import programatically via the ModelOps Python SDK. \n",
    "\n",
    "You may be wondering why you can't just directly insert the onnx or pmml model directly into the database table. And the answer is you can. However, with ModelOps, you get full governance around this model deployment, including data drift and model monitoring and alerting. \n",
    "\n",
    "\n",
    "### View Published Models\n",
    "\n",
    "Once deployed via ModelOps, we can view the models published to vantage by querying the table they are published to. Note this information is available via the AOA APIs also.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 250\n",
    "pd.read_sql(\"SELECT TOP 2 * FROM aoa_byom_models\", get_connection())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-Demand Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version=\"1dbe5430-f8c5-4d32-b26c-a02476cba510\"\n",
    "\n",
    "model = DataFrame.from_query(f\"\"\"\n",
    "SELECT * FROM aoa_byom_models \n",
    "    WHERE model_version='{model_version}'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "preds = PMMLPredict(\n",
    "        modeldata=model,\n",
    "        newdata=DataFrame.from_query(\"SELECT * FROM pima_patient_features WHERE patientid MOD 5 = 0\"),\n",
    "        accumulate=['PatientId'])\n",
    "\n",
    "preds.result.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT * FROM {byom_db}.PMMLPredict (\n",
    "    ON (SELECT * FROM pima_patient_features WHERE patientid MOD 5 = 0) AS DataTable\n",
    "    ON (SELECT * FROM aoa_byom_models \n",
    "            WHERE model_version='{model_version}') AS ModelTable DIMENSION\n",
    "    USING\n",
    "      Accumulate ('patientid')\n",
    ") AS td;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, get_connection()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT td.* FROM {byom_db}.ONNXPredict (\n",
    "    ON (SELECT * FROM pima_patient_features WHERE patientid MOD 5 = 0) AS DataTable\n",
    "    ON (SELECT * FROM aoa_byom_models \n",
    "            WHERE model_version='onnx-test') AS ModelTable DIMENSION\n",
    "    USING\n",
    "      Accumulate ('patientid')\n",
    ") AS td;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, get_connection()).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom BYOM Evaluation Logic\n",
    "\n",
    "You can define custom evaluation logic for BYOM models in ModelOps. This allows you to define your own charts, metrics etc that are to be created and captured as part of evaluation / comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aoa.stats.stats import _capture_stats, _NpEncoder\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "\n",
    "train_df = DataFrame.from_query(\"\"\"\n",
    "SELECT \n",
    "    F.*, D.hasdiabetes \n",
    "FROM pima_patient_features F\n",
    "JOIN pima_patient_diagnoses D\n",
    "    ON F.patientid = D.patientid \n",
    "    WHERE F.patientid MOD 5 <> 0\n",
    "\"\"\")\n",
    "\n",
    "data_stats = _capture_stats(df=train_df,\n",
    "                            features=features,\n",
    "                            targets=[target],\n",
    "                            categorical=[target],\n",
    "                            feature_metadata_fqtn=f\"{database}.aoa_feature_metadata\")\n",
    "\n",
    "with open(\"data_stats.json\", 'w+') as f:\n",
    "    json.dump(data_stats, f, indent=2, cls=_NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from teradataml import (\n",
    "    get_context,\n",
    "    DataFrame,\n",
    "    PMMLPredict,\n",
    "    configure\n",
    ")\n",
    "from aoa import (\n",
    "    record_evaluation_stats,\n",
    "    aoa_create_context,\n",
    "    store_byom_tmp,\n",
    "    ModelContext\n",
    ")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cf, img_filename):\n",
    "    import itertools\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(cf, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xticks([0, 1], ['0', '1'])\n",
    "    plt.yticks([0, 1], ['0', '1'])\n",
    "\n",
    "    thresh = cf.max() / 2.\n",
    "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
    "        plt.text(j, i, format(cf[i, j], 'd'), horizontalalignment='center',\n",
    "                 color='white' if cf[i, j] > thresh else 'black')\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    \n",
    "    # this evaluation.py can hanlde both onnx and pmml. usually, you would only need to support one but for \n",
    "    # demo purposes, we will show with both as we produce both onnx and pmml in this notebook.\n",
    "    \n",
    "    import glob\n",
    "    for file_name in glob.glob(f\"{context.artifact_input_path}/model.*\"):\n",
    "        model_type = file_name.split(\".\")[-1]\n",
    "    \n",
    "    with open(f\"{context.artifact_input_path}/model.{model_type}\", \"rb\") as f:\n",
    "        model_bytes = f.read()\n",
    "        \n",
    "    model = store_byom_tmp(get_context(), \"byom_models_tmp\", context.model_version, model_bytes)\n",
    "\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "\n",
    "    if model_type.upper() == \"ONNX\":\n",
    "        byom_target_sql = \"CAST(CAST(json_report AS JSON).JSONExtractValue('$.output_label[0]') AS INT)\"\n",
    "        mldb = os.environ.get(\"AOA_BYOM_INSTALL_DB\", \"MLDB\")\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT sc.{context.dataset_info.entity_key}, {target_name}, sc.json_report\n",
    "                FROM {mldb}.ONNXPredict(\n",
    "                    ON ({context.dataset_info.sql}) AS DataTable\n",
    "                    ON (SELECT model_version as model_id, model FROM byom_models_tmp) AS ModelTable DIMENSION\n",
    "                    USING\n",
    "                        Accumulate('{context.dataset_info.entity_key}', '{target_name}')\n",
    "            ) sc;\n",
    "        \"\"\"\n",
    "\n",
    "        predictions_df = DataFrame.from_query(query)\n",
    "        \n",
    "    elif model_type.upper() == \"PMML\":\n",
    "        byom_target_sql = \"CAST(CAST(json_report AS JSON).JSONExtractValue('$.predicted_HasDiabetes') AS INT)\"\n",
    "        \n",
    "        pmml = PMMLPredict(\n",
    "            modeldata=model,\n",
    "            newdata=DataFrame.from_query(context.dataset_info.sql),\n",
    "            accumulate=[context.dataset_info.entity_key, target_name])\n",
    "        \n",
    "        predictions_df = pmml.result\n",
    "\n",
    "    predictions_df.to_sql(table_name=\"predictions_tmp\", if_exists=\"replace\", temporary=True)\n",
    "\n",
    "    metrics_df = DataFrame.from_query(f\"\"\"\n",
    "    SELECT \n",
    "        HasDiabetes as y_test, \n",
    "        {byom_target_sql} as y_pred\n",
    "        FROM predictions_tmp\n",
    "    \"\"\")\n",
    "    metrics_df = metrics_df.to_pandas()\n",
    "\n",
    "    y_pred = metrics_df[[\"y_pred\"]]\n",
    "    y_test = metrics_df[[\"y_test\"]]\n",
    "\n",
    "    evaluation = {\n",
    "        'Accuracy': '{:.2f}'.format(metrics.accuracy_score(y_test, y_pred)),\n",
    "        'Recall': '{:.2f}'.format(metrics.recall_score(y_test, y_pred)),\n",
    "        'Precision': '{:.2f}'.format(metrics.precision_score(y_test, y_pred)),\n",
    "        'f1-score': '{:.2f}'.format(metrics.f1_score(y_test, y_pred))\n",
    "    }\n",
    "\n",
    "    with open(f\"{context.artifact_output_path}/metrics.json\", \"w+\") as f:\n",
    "        json.dump(evaluation, f)\n",
    "\n",
    "    # create confusion matrix plot\n",
    "    cf = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plot_confusion_matrix(cf, f\"{context.artifact_output_path}/confusion_matrix\")\n",
    "\n",
    "    # calculate stats if training stats exist\n",
    "    if os.path.exists(f\"{context.artifact_input_path}/data_stats.json\"):\n",
    "        record_evaluation_stats(features_df=DataFrame.from_query(context.dataset_info.sql),\n",
    "                                predicted_df=DataFrame(\"predictions_tmp\"),\n",
    "                                context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aoa import ModelContext, DatasetInfo\n",
    "\n",
    "# Define the ModelContext to test with. The ModelContext is created and managed automatically by ModelOps \n",
    "# when it executes your code via CLI / UI. However, for testing in the notebook, you can define as follows\n",
    "\n",
    "# define the evaluation dataset \n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    F.*, D.hasdiabetes \n",
    "FROM PIMA_PATIENT_FEATURES F \n",
    "JOIN PIMA_PATIENT_DIAGNOSES D\n",
    "ON F.patientid = D.patientid\n",
    "    WHERE D.patientid MOD 5 = 0\n",
    "\"\"\"\n",
    "\n",
    "feature_metadata =  {\n",
    "    \"database\": database,\n",
    "    \"table\": \"aoa_feature_metadata\"\n",
    "}\n",
    "\n",
    "entity_key = \"PatientId\"\n",
    "target_names = [\"HasDiabetes\"]\n",
    "feature_names = [\"NumTimesPrg\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\", \"Age\"]\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata)\n",
    "\n",
    "ctx = ModelContext(hyperparams={},\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"/tmp\",\n",
    "                   artifact_input_path=\"./\",\n",
    "                   model_version=\"v1\",\n",
    "                   model_table=\"aoa_model_v1\")\n",
    "\n",
    "\n",
    "# drop volatile table from session if executing multiple times\n",
    "try:\n",
    "    get_context().execute(f\"DROP TABLE byom_models_tmp\")\n",
    "except: \n",
    "    pass\n",
    "\n",
    "evaluate(context=ctx)\n",
    "\n",
    "# view evaluation results\n",
    "with open(f\"{ctx.artifact_output_path}/metrics.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.from_query(\"SELECT PatientId, HasDiabetes, json_report FROM predictions_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39]",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
