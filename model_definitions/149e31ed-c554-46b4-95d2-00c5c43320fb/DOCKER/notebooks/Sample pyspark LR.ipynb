{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.226.4.26:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10a5186d8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# where your spark installation and sample data is \n",
    "spark_demo_data_path = os.environ[\"SPARK_HOME\"] + \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../training.py\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "def train(spark, data_conf, model_conf, **kwargs):\n",
    "    hyperparams = model_conf[\"hyperParameters\"]\n",
    "\n",
    "    # Load training data - standard spark dataset data/mllib/sample_libsvm_data.txt\n",
    "    training = spark.read.format(\"libsvm\").load(data_conf[\"data_path\"])\n",
    "\n",
    "    lr = LogisticRegression(maxIter=hyperparams[\"maxIter\"],\n",
    "                            regParam=hyperparams[\"regParam\"],\n",
    "                            elasticNetParam=hyperparams[\"elasticNetParam\"])\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    lr_model = lr.fit(training)\n",
    "\n",
    "    # Print the coefficients and intercept for logistic regression\n",
    "    print(\"Coefficients: {}\".format(str(lr_model.coefficients)))\n",
    "    print(\"Intercept: {}\".format(str(lr_model.intercept)))\n",
    "\n",
    "    print(\"Finished training\")\n",
    "\n",
    "    # export model artefacts to models/ folder\n",
    "\n",
    "    print(\"Saved trained model\")\n",
    "    lr_model.write().overwrite() \\\n",
    "        .save(spark.sparkContext.getConf().get(\"spark.ammf.model.path\", \"file:///tmp/lr\"))\n",
    "    \n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Coefficients: (692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.353983524188197e-05,-9.102738505589466e-05,-0.00019467430546904298,-0.00020300642473486668,-3.1476183314863995e-05,-6.842977602660743e-05,1.5883626898239883e-05,1.4023497091372047e-05,0.00035432047524968605,0.00011443272898171087,0.00010016712383666666,0.0006014109303795481,0.0002840248179122762,-0.00011541084736508837,0.000385996886312906,0.000635019557424107,-0.00011506412384575676,-0.00015271865864986808,0.0002804933808994214,0.0006070117471191634,-0.0002008459663247437,-0.0001421075579290126,0.0002739010341160883,0.00027730456244968115,-9.838027027269332e-05,-0.0003808522443517704,-0.00025315198008555033,0.00027747714770754307,-0.0002443619763919199,-0.0015394744687597765,-0.00023073328411331293])\n",
      "Intercept: 0.22456315961250325\n",
      "Finished training\n",
      "Saved trained model\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_conf = json.load(open(\"../../config.json\", \"r\"))\n",
    "data_conf = {\n",
    "    \"data_path\": spark_demo_data_path + \"/mllib/sample_libsvm_data.txt\"\n",
    "}\n",
    "\n",
    "lr_model = train(spark, data_conf, model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set areaUnderROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = lr_model.summary\n",
    "roc = summary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set areaUnderROC: ' + str(summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[127,128,129...|[0.73765439548910...|[0.67648272431605...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-1.2286964884747...|[0.22640965216205...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-1.2596645795726...|[0.22103163838284...|       1.0|\n",
      "|  1.0|(692,[152,153,154...|[-1.0845333752697...|[0.25264907653471...|       1.0|\n",
      "|  1.0|(692,[151,152,153...|[-1.2371063245185...|[0.22494007343582...|       1.0|\n",
      "|  0.0|(692,[129,130,131...|[0.73839617859787...|[0.67664504514663...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-1.2123284339889...|[0.22928932070495...|       1.0|\n",
      "|  1.0|(692,[99,100,101,...|[-0.2350856805053...|[0.44149776057216...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[0.10357406008713...|[0.52587039191803...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[0.72217476589208...|[0.67308573545409...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "lr_model = LogisticRegressionModel.load(\"file:///tmp/lr\")\n",
    "\n",
    "test = spark.read.format(\"libsvm\").load(spark_demo_data_path + \"/mllib/sample_libsvm_data.txt\")\n",
    "predictions = lr_model.transform(test)\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../scoring.py\n",
    "import json \n",
    "\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "def evaluate(spark, data_conf, model_conf, **kwargs):\n",
    "    lr_model = LogisticRegressionModel.load(spark.sparkContext._conf.get(\"spark.ammf.model.path\", \"file:///tmp/lr\"))\n",
    "    test = spark.read.format(\"libsvm\").load(data_conf[\"data_path\"])\n",
    "    predictions = lr_model.transform(test)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    roc = evaluator.evaluate(predictions)\n",
    "    print('Test Area Under ROC: {}'.format(roc))\n",
    "    \n",
    "    with open(\"models/evaluation.json\", \"w+\") as f:\n",
    "        json.dump({'roc': roc}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_conf = json.load(open(\"../../config.json\", \"r\"))\n",
    "data_conf = {\n",
    "    \"data_path\": spark_demo_data_path + \"/mllib/sample_libsvm_data.txt\"\n",
    "}\n",
    "\n",
    "evaluate(spark, data_conf, model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark 2.2",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
